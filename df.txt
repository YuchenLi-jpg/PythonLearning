Programming Skills Supplements
Use Flight.csv containing flights number, origin, destination, passenger, country
For each State, I am interested in (a) the total number of passengers flying out of it and (b) the total number of flights flying out of it. 

1. Scala version

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types._

object df_final {
    def main(spark: SparkSession) = {
        // manual schema
        val myschema = new StructType()
                             .add("ITIN_ID", StringType, true)
                             .add("YEAR", StringType, true) 
                             .add("QUARTER", StringType,true) 
                             .add("ORIGIN", StringType, true) 
                             .add("ORIGIN_STATE_NM", StringType, true) 
                             .add("DEST", StringType, true) 
                             .add("DEST_STATE_NM", StringType, true) 
                             .add("PASSENGERS", DoubleType, true)
        // read csv, with head = true, and schema specification
        val df = spark.read.format("csv")
                           .option("delimiter", ",")
                           .option("header", "true")
                           .schema(myschema)
                           .load("/datasets/flight")
        // selection corresponding cols, and create a column as 1.0
        val orders = df.selectExpr("ORIGIN_STATE_NM", "PASSENGERS", "1.0 as FLIGHT_COUNT")
        // group by each state, for each state, calculate the sum of passengers, and sum of 1.0.
        val grouped = orders.groupBy("ORIGIN_STATE_NM").agg(sum("PASSENGERS").alias("Number_of_passengers"), sum("FLIGHT_COUNT").alias("Number_of_flights"))
        grouped.write.format("csv").option("mode", "ignore").save("/user/ybl5346/output_df")
    }
}

 // Array((Montana,(27294.0,34071.0)), (California,(289809.0,613244.0)), (Washington,(80341.0,158700.0)), (Massachusetts,(42226.0,99458.0)))

2. Hadoop (Python) version

from mrjob.job import MRJob # MRJob version

class Flight(MRJob): #MRJob version
    def mapper_init(self):
        self.flights = {}
        self.passengers = {}
        
    def mapper(self, key, line):
        if line.startswith("ITIN_ID"):
            pass
        else:
            parts = line.split(",")
            state = parts[4]
            passengers = float(parts[7])
            self.flights[state] = 1.0 + self.flights.get(state,0)
            self.passengers[state] = passengers + self.passengers.get(state,0)
            # generate two dictionaries:  self.flights{state: flight_count},  self.passengers{state: passengers_count}
            
    def mapper_final(self):
        for i in self.flights:
            yield i, (self.flights[i], "flight")
        for j in self.passengers:
            yield j, (self.passengers[j], "passenger")
            # this should be (state, (flight_count, "flight"))
                   
    # the mapper would send pairs to reducer:   (state, [(1, flight),(2, passenger)]) same key will be grouped together
    def reducer(self, key, values):
        flight_count = 0
        passenger_count = 0
        for values in values:
            if values[1] == "flight":
                flight_count += values[0]
            if values[1] == "passenger":
                passenger_count += values[0]
        yield key, (passenger_count, flight_count)
             
            

if __name__ == '__main__':
    Flight.run() # MRJob version
